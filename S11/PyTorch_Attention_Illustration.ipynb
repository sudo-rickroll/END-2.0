{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "PyTorch Attention Illustration.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6nkOSBkKiE1Y"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "%matplotlib inline\r\n",
        "\r\n",
        "from __future__ import unicode_literals, print_function, division\r\n",
        "from io import open\r\n",
        "import unicodedata\r\n",
        "import string\r\n",
        "import re\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch import optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "!wget https://download.pytorch.org/tutorial/data.zip\r\n",
        "\r\n",
        "!unzip data.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-07-24 13:17:37--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.32.199.96, 13.32.199.123, 13.32.199.15, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.32.199.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip.3’\n",
            "\n",
            "\rdata.zip.3            0%[                    ]       0  --.-KB/s               \rdata.zip.3          100%[===================>]   2.75M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-07-24 13:17:37 (73.5 MB/s) - ‘data.zip.3’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4wolA2hcrGF",
        "outputId": "71345171-e0a2-4dad-d0e5-dc588e5124a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "D1zUUpIPwGNI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "SOS_token = 0\r\n",
        "EOS_token = 1\r\n",
        "\r\n",
        "\r\n",
        "class Lang:\r\n",
        "    def __init__(self, name):\r\n",
        "        self.name = name\r\n",
        "        self.word2index = {}\r\n",
        "        self.word2count = {}\r\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\r\n",
        "        self.n_words = 2  # Count SOS and EOS\r\n",
        "\r\n",
        "    def addSentence(self, sentence):\r\n",
        "        for word in sentence.split(' '):\r\n",
        "            self.addWord(word)\r\n",
        "\r\n",
        "    def addWord(self, word):\r\n",
        "        if word not in self.word2index:\r\n",
        "            self.word2index[word] = self.n_words\r\n",
        "            self.word2count[word] = 1\r\n",
        "            self.index2word[self.n_words] = word\r\n",
        "            self.n_words += 1\r\n",
        "        else:\r\n",
        "            self.word2count[word] += 1\r\n",
        "\r\n",
        "# Turn a Unicode string to plain ASCII, thanks to\r\n",
        "# https://stackoverflow.com/a/518232/2809427\r\n",
        "def unicodeToAscii(s):\r\n",
        "    return ''.join(\r\n",
        "        c for c in unicodedata.normalize('NFD', s)\r\n",
        "        if unicodedata.category(c) != 'Mn'\r\n",
        "    )\r\n",
        "\r\n",
        "# Lowercase, trim, and remove non-letter characters\r\n",
        "\r\n",
        "\r\n",
        "def normalizeString(s):\r\n",
        "    s = unicodeToAscii(s.lower().strip())\r\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\r\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\r\n",
        "    return s\r\n",
        "\r\n",
        "def readLangs(lang1, lang2, reverse=False):\r\n",
        "    print(\"Reading lines...\")\r\n",
        "\r\n",
        "    # Read the file and split into lines\r\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\r\n",
        "        read().strip().split('\\n')\r\n",
        "\r\n",
        "    # Split every line into pairs and normalize\r\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\r\n",
        "\r\n",
        "    # Reverse pairs, make Lang instances\r\n",
        "    if reverse:\r\n",
        "        pairs = [list(reversed(p)) for p in pairs]\r\n",
        "        input_lang = Lang(lang2)\r\n",
        "        output_lang = Lang(lang1)\r\n",
        "    else:\r\n",
        "        input_lang = Lang(lang1)\r\n",
        "        output_lang = Lang(lang2)\r\n",
        "\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n",
        "\r\n",
        "MAX_LENGTH = 10\r\n",
        "\r\n",
        "eng_prefixes = (\r\n",
        "    \"i am \", \"i m \",\r\n",
        "    \"he is\", \"he s \",\r\n",
        "    \"she is\", \"she s \",\r\n",
        "    \"you are\", \"you re \",\r\n",
        "    \"we are\", \"we re \",\r\n",
        "    \"they are\", \"they re \"\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def filterPair(p):\r\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\r\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\r\n",
        "        p[1].startswith(eng_prefixes)\r\n",
        "\r\n",
        "\r\n",
        "def filterPairs(pairs):\r\n",
        "    return [pair for pair in pairs if filterPair(pair)]\r\n",
        "\r\n",
        "\r\n",
        "def prepareData(lang1, lang2, reverse=False):\r\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\r\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\r\n",
        "    pairs = filterPairs(pairs)\r\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\r\n",
        "    print(\"Counting words...\")\r\n",
        "    for pair in pairs:\r\n",
        "        input_lang.addSentence(pair[0])\r\n",
        "        output_lang.addSentence(pair[1])\r\n",
        "    print(\"Counted words:\")\r\n",
        "    print(input_lang.name, input_lang.n_words)\r\n",
        "    print(output_lang.name, output_lang.n_words)\r\n",
        "    return input_lang, output_lang, pairs\r\n",
        "\r\n",
        "\r\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\r\n",
        "print(random.choice(pairs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['je l emporte .', 'i m winning .']\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOvRiBM1dmNf",
        "outputId": "3e773402-e466-41ed-ed2a-5cc20adcdd6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "type(pairs)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vwlh_8Id00Q",
        "outputId": "68878c5a-ad84-4dff-af77-4d4d822833d9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "pairs[0:5]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['j ai ans .', 'i m .'],\n",
              " ['je vais bien .', 'i m ok .'],\n",
              " ['ca va .', 'i m ok .'],\n",
              " ['je suis gras .', 'i m fat .'],\n",
              " ['je suis gros .', 'i m fat .']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY4XuElfd9kl",
        "outputId": "b46faca6-4b5c-4b71-9495-8e471a57614c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "help(input_lang)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Lang in module __main__ object:\n",
            "\n",
            "class Lang(builtins.object)\n",
            " |  Lang(name)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, name)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  addSentence(self, sentence)\n",
            " |  \n",
            " |  addWord(self, word)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj-cHSHigpE7",
        "outputId": "334d46f9-46f2-4584-9708-658b0e5d1dc7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "input_lang.n_words, output_lang.n_words"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4345, 2803)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi-oeYO5hy2e",
        "outputId": "8d0bf6c6-3241-47aa-e355-8779a2c7eb81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "input_size = input_lang.n_words"
      ],
      "outputs": [],
      "metadata": {
        "id": "HohMsxKyiIJu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "sample = random.choice(pairs)\r\n",
        "sample"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tu n es pas different .', 'you re no different .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI0AvyzwiV9k",
        "outputId": "4bd7987a-f27b-433d-90d7-721c34ea35d9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "src = sample[0]\r\n",
        "trg = sample[1]"
      ],
      "outputs": [],
      "metadata": {
        "id": "l1drC51RxnHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "src = [input_lang.word2index[i] for i in src.split(\" \")]\r\n",
        "trg = [output_lang.word2index[i] for i in trg.split(\" \")]"
      ],
      "outputs": [],
      "metadata": {
        "id": "_y36gZs6ycpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "src.append(EOS_token), trg.append(EOS_token)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjmuZTXx0FiB",
        "outputId": "a5132508-5767-431b-a5d2-ce642ae9af76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "src = torch.tensor(src)\r\n",
        "trg = torch.tensor(trg)"
      ],
      "outputs": [],
      "metadata": {
        "id": "W5Yt8wjy0ovk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "src, trg"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 210,  245,  211,  246, 1442,    5,    1]),\n",
              " tensor([129,  78, 183, 373,   4,   1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_0Jq9SO0yZA",
        "outputId": "ada6f723-1d46-4a47-e85f-cb922b795c88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "src.shape[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXiyg4ppCJ3A",
        "outputId": "0a80dbfd-3b36-464e-8482-729a1e088d38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialising Dimensions"
      ],
      "metadata": {
        "id": "2zMI7IMZwRYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "input_dim = input_lang.n_words\r\n",
        "embedding_dim = 256\r\n",
        "hidden_dim = 256\r\n",
        "output_dim = output_lang.n_words"
      ],
      "outputs": [],
      "metadata": {
        "id": "ELaix_Yu5hrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder (First two words)"
      ],
      "metadata": {
        "id": "ma4nYCK1vy7r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "encoder_embedding = nn.Embedding(input_dim, embedding_dim)\r\n",
        "encoder_rnn = nn.LSTM(embedding_dim, hidden_dim)\r\n",
        "encoder_outputs = torch.zeros((src.shape[0], 1, embedding_dim))\r\n",
        "encoder_hidden = torch.zeros(1, 1, 256)\r\n",
        "encoder_cell = torch.zeros(1, 1, 256)\r\n",
        "for i in range(2):\r\n",
        "  encoder_embedded = encoder_embedding(src[i]).reshape(1, 1, -1)\r\n",
        "  encoder_output, (encoder_hidden, encoder_cell) = encoder_rnn(encoder_embedded, (encoder_hidden, encoder_cell))\r\n",
        "  encoder_outputs[i] = encoder_output[0]\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "S33Nl_F7J981"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder (First two words)"
      ],
      "metadata": {
        "id": "eZRH_C_grQOG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "trg = torch.cat((torch.tensor([SOS_token]), trg))\r\n",
        "decoder_hidden = encoder_hidden\r\n",
        "decoder_cell = encoder_cell\r\n",
        "attention_weight_layer = nn.Linear(hidden_dim + embedding_dim, src.shape[0])\r\n",
        "decoder_pre_rnn = nn.Linear(hidden_dim + embedding_dim, embedding_dim)\r\n",
        "output_layer = nn.Linear(hidden_dim, output_lang.n_words)\r\n",
        "for i in range(2):\r\n",
        "  decoder_embedding = nn.Embedding(output_dim, embedding_dim)\r\n",
        "  decoder_rnn = nn.LSTM(embedding_dim, hidden_dim)\r\n",
        "  decoder_embedded = decoder_embedding(trg[i])  \r\n",
        "  attention_weights = F.softmax(attention_weight_layer(torch.cat((decoder_hidden, decoder_embedded.reshape(1, 1, -1)), dim=2)), dim = 2)\r\n",
        "  attn_applied = torch.bmm(attention_weights, encoder_outputs.squeeze(1).unsqueeze(0))  \r\n",
        "  decoded_output, (decoded_hidden, decoded_cell) = decoder_rnn(decoder_pre_rnn(torch.cat((attn_applied, decoder_embedded.reshape(1, 1, -1)), dim = 2)), (decoder_hidden, decoder_cell))\r\n",
        "  output = F.softmax(output_layer(decoded_output), dim = 2)\r\n",
        "  print(f\"Output predicted by word {i + 1} from decoder is '{output_lang.index2word[output.argmax(dim=2).item()]}'\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output predicted by word 1 from decoder is 'lacking'\n",
            "Output predicted by word 2 from decoder is 'lonely'\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k81E9FBdm2-W",
        "outputId": "310f2fa5-c6ad-4f2c-c370-c6eef54a7d81"
      }
    }
  ]
}