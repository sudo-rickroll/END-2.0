{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_using_LSTM_RNN 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S318CunI24Kj"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqH8vMqTpuca",
        "outputId": "58de98c0-1259-41c8-916a-c8f8291a2b17"
      },
      "source": [
        "!pip install pytreebank"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Building wheels for collected packages: pytreebank\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp37-none-any.whl size=37070 sha256=9c2ede937c249cc31eaac14cc4567cf12db5ec1632d48b41343c7871d894b8ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "Successfully built pytreebank\n",
            "Installing collected packages: pytreebank\n",
            "Successfully installed pytreebank-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oicj4H1hcKz5",
        "outputId": "a2ffbf03-4d83-49c7-c346-d22e9920d0a5"
      },
      "source": [
        "!pip install numpy git+https://github.com/makcedward/nlpaug.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/makcedward/nlpaug.git\n",
            "  Cloning https://github.com/makcedward/nlpaug.git to /tmp/pip-req-build-joexxkku\n",
            "  Running command git clone -q https://github.com/makcedward/nlpaug.git /tmp/pip-req-build-joexxkku\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Building wheels for collected packages: nlpaug\n",
            "  Building wheel for nlpaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlpaug: filename=nlpaug-1.1.3-cp37-none-any.whl size=837629 sha256=f68e848101e558e1ff9452d415163b95fa2b213f8ea8c5759f1f024fd3c8d880\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lwg9ug_j/wheels/2b/ef/30/a4e22f9a97373c9ab6763670c94aa5e111b0b956983f3892a4\n",
            "Successfully built nlpaug\n",
            "Installing collected packages: nlpaug\n",
            "Successfully installed nlpaug-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnj4UlH-qBvX"
      },
      "source": [
        "import pytreebank\n",
        "import pandas as pd\n",
        "import random\n",
        "import nlpaug.augmenter.word as naw"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaxbfTwEp_53"
      },
      "source": [
        "dataset = pytreebank.load_sst()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCskhn69s1Q1",
        "outputId": "6a9aabcb-b61f-4d8d-dd67-358a429ebe74"
      },
      "source": [
        "[dataset.keys()]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[dict_keys(['train', 'test', 'dev'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGa1aGf-8FoX",
        "outputId": "4014a09e-74f2-45b4-a843-a4f91bf0b53c"
      },
      "source": [
        "len(dataset['train']), len(dataset['test']), len(dataset['dev'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8544, 2210, 1101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iCSczZbuGLx"
      },
      "source": [
        "train_df = pd.DataFrame({'sentence' : [dataset['train'][i].to_labeled_lines()[0][1] for i in range(len(dataset['train']))], 'labels' : [dataset['train'][i].to_labeled_lines()[0][0] for i in range(len(dataset['train']))]})\n",
        "test_df = pd.DataFrame({'sentence' : [dataset['test'][i].to_labeled_lines()[0][1] for i in range(len(dataset['test']))], 'labels' : [dataset['test'][i].to_labeled_lines()[0][0] for i in range(len(dataset['test']))]})\n",
        "val_df = pd.DataFrame({'sentence' : [dataset['dev'][i].to_labeled_lines()[0][1] for i in range(len(dataset['dev']))], 'labels' : [dataset['dev'][i].to_labeled_lines()[0][0] for i in range(len(dataset['dev']))]})\n",
        "df = pd.concat([train_df, test_df, val_df]).reset_index(drop=True)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-ylf6C6BJD",
        "outputId": "684868d6-4372-46b9-856f-8875e6f9cdf4"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxhrQox6Ju3",
        "outputId": "927fe9ec-630e-4096-9d7e-b7791dd7b729"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3140\n",
              "3    3111\n",
              "2    2242\n",
              "4    1852\n",
              "0    1510\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2reTNPc3v9RW"
      },
      "source": [
        "df_train = df[:int(0.7*len(df))]\n",
        "df_val = df[len(df_train):].reset_index(drop=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma2WESJtwP1A",
        "outputId": "e6b87215-6f62-4def-ca58-2b0f49724049"
      },
      "source": [
        "len(df_train), len(df_val)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8298, 3557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYgC1u2VZEvq"
      },
      "source": [
        "indexes = random.choices(list(range(len(df_train))), k = int(len(df_train)*0.05))                         \n",
        "sentences = [df_train['sentence'][i] for i in indexes]\n",
        "augmented_sentences = []"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P720-Gfwf3he"
      },
      "source": [
        "aug_del = naw.RandomWordAug(aug_p = 1)\n",
        "aug_swap = naw.RandomWordAug(action=\"swap\", aug_p = 1)\n",
        "for i in range(len(sentences)//2):  \n",
        "  augmented_text = aug_del.augment(sentences[i])  \n",
        "  augmented_sentences += [augmented_text]\n",
        "for i in range(len(sentences)//2, len(sentences)):  \n",
        "  augmented_text = aug_swap.augment(sentences[i])  \n",
        "  augmented_sentences += [augmented_text]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuCNipmkvmlq",
        "outputId": "60293710-2e3e-4d6c-c7ec-0116bf504241"
      },
      "source": [
        "len(augmented_sentences)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EUsLsODlZuq"
      },
      "source": [
        "df_train_aug = pd.DataFrame({'sentence': augmented_sentences, 'labels': [df_train['labels'][i] for i in indexes]})\n",
        "df_aug = pd.concat([df_train, df_train_aug]).reset_index(drop=True)\n",
        "df_aug = df_aug.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55c-wP_Go20c",
        "outputId": "ea3c0da8-ad5e-4ff8-ba68-7c327095e32f"
      },
      "source": [
        "len(df_aug)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q3UIsHNtO7o"
      },
      "source": [
        "# Model Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIyapAa6Pjr"
      },
      "source": [
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kqZx2hG6e4Q"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wofFldA_tdYH"
      },
      "source": [
        "df_train = df_aug\n",
        "df_val = df_val"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDBbe8Ad6yhE"
      },
      "source": [
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Sentence = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('sentence', Sentence), ('label', Label)]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "example_train = [torchtext.legacy.data.Example.fromlist([df_train.sentence[i],df_train.labels[i]], fields) for i in range(df_train.shape[0])] \n",
        "example_val = [torchtext.legacy.data.Example.fromlist([df_val.sentence[i],df_val.labels[i]], fields) for i in range(df_val.shape[0])] \n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "train = torchtext.legacy.data.Dataset(example_train, fields)\n",
        "valid = torchtext.legacy.data.Dataset(example_val, fields)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsToO_PEu6zJ",
        "outputId": "45b6c9f1-4cb8-40cd-9ead-352183bf3df8"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8712, 3557)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX5_chR-FvqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "8387ffd6-5610-4cab-ea7c-feb037e308e5"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Even these tales of just seven children seem a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A sterling film - a cross between Boys Do n't ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Imagine Kevin Smith , the blasphemous bad boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Imagine if you will a Tony Hawk skating video ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dignified CEO 's meet at a rustic retreat and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  labels\n",
              "0  Even these tales of just seven children seem a...       2\n",
              "1  A sterling film - a cross between Boys Do n't ...       2\n",
              "2  Imagine Kevin Smith , the blasphemous bad boy ...       0\n",
              "3  Imagine if you will a Tony Hawk skating video ...       1\n",
              "4  Dignified CEO 's meet at a rustic retreat and ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Sentence.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "d90c59b9-d47c-4c4e-f9aa-ccf5c1312775"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  17104\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('.', 8243), (',', 7347), ('the', 6137), ('and', 4451), ('of', 4398), ('a', 4360), ('to', 2985), ('-', 2885), ('is', 2477), (\"'s\", 2474)]\n",
            "Labels :  defaultdict(None, {1: 0, 3: 1, 2: 2, 4: 3, 0: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBmMQQcX9SZk",
        "outputId": "c2a519c5-e227-4f99-e361-4478b95deeb5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 16, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kgqqK75FLEV",
        "outputId": "1f6af51d-1e80-47b0-c0e6-16516d210a7d"
      },
      "source": [
        "next(iter(train_iterator))\n",
        "#len(train.examples[11].tweet)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 16]\n",
              "\t[.sentence]:('[torch.cuda.LongTensor of size 16x10 (GPU 0)]', '[torch.cuda.LongTensor of size 16 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 16 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5py1Rwf3KlZ"
      },
      "source": [
        "# Building Model and Prediction Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQnNcH6-oZZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        #output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return dense_outputs[0]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = 5\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRextCcAASGO",
        "outputId": "b121fff2-05b8-451a-c111-c2926d1806e8"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(17104, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "The model has 5,373,305 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \n",
        "        #print(predictions, batch.label)\n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze() \n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7UPwN0KAvVq",
        "outputId": "48573960-abe4-42d5-f496-0d7648109329"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.584 | Train Acc: 25.99%\n",
            "\t Val. Loss: 1.572 |  Val. Acc: 26.83% \n",
            "\n",
            "\tTrain Loss: 1.573 | Train Acc: 26.67%\n",
            "\t Val. Loss: 1.569 |  Val. Acc: 27.09% \n",
            "\n",
            "\tTrain Loss: 1.570 | Train Acc: 27.08%\n",
            "\t Val. Loss: 1.568 |  Val. Acc: 26.15% \n",
            "\n",
            "\tTrain Loss: 1.568 | Train Acc: 27.35%\n",
            "\t Val. Loss: 1.568 |  Val. Acc: 27.00% \n",
            "\n",
            "\tTrain Loss: 1.567 | Train Acc: 28.31%\n",
            "\t Val. Loss: 1.567 |  Val. Acc: 26.95% \n",
            "\n",
            "\tTrain Loss: 1.565 | Train Acc: 28.70%\n",
            "\t Val. Loss: 1.566 |  Val. Acc: 27.09% \n",
            "\n",
            "\tTrain Loss: 1.563 | Train Acc: 29.24%\n",
            "\t Val. Loss: 1.566 |  Val. Acc: 27.12% \n",
            "\n",
            "\tTrain Loss: 1.561 | Train Acc: 29.70%\n",
            "\t Val. Loss: 1.565 |  Val. Acc: 26.98% \n",
            "\n",
            "\tTrain Loss: 1.559 | Train Acc: 29.52%\n",
            "\t Val. Loss: 1.564 |  Val. Acc: 27.23% \n",
            "\n",
            "\tTrain Loss: 1.557 | Train Acc: 30.29%\n",
            "\t Val. Loss: 1.564 |  Val. Acc: 27.54% \n",
            "\n",
            "\tTrain Loss: 1.555 | Train Acc: 30.57%\n",
            "\t Val. Loss: 1.563 |  Val. Acc: 27.06% \n",
            "\n",
            "\tTrain Loss: 1.553 | Train Acc: 30.94%\n",
            "\t Val. Loss: 1.562 |  Val. Acc: 27.29% \n",
            "\n",
            "\tTrain Loss: 1.550 | Train Acc: 31.31%\n",
            "\t Val. Loss: 1.561 |  Val. Acc: 27.09% \n",
            "\n",
            "\tTrain Loss: 1.548 | Train Acc: 31.57%\n",
            "\t Val. Loss: 1.561 |  Val. Acc: 27.65% \n",
            "\n",
            "\tTrain Loss: 1.545 | Train Acc: 31.67%\n",
            "\t Val. Loss: 1.560 |  Val. Acc: 27.93% \n",
            "\n",
            "\tTrain Loss: 1.542 | Train Acc: 31.94%\n",
            "\t Val. Loss: 1.559 |  Val. Acc: 27.65% \n",
            "\n",
            "\tTrain Loss: 1.539 | Train Acc: 32.27%\n",
            "\t Val. Loss: 1.558 |  Val. Acc: 27.71% \n",
            "\n",
            "\tTrain Loss: 1.536 | Train Acc: 32.47%\n",
            "\t Val. Loss: 1.558 |  Val. Acc: 27.85% \n",
            "\n",
            "\tTrain Loss: 1.533 | Train Acc: 32.82%\n",
            "\t Val. Loss: 1.557 |  Val. Acc: 28.24% \n",
            "\n",
            "\tTrain Loss: 1.529 | Train Acc: 33.10%\n",
            "\t Val. Loss: 1.556 |  Val. Acc: 28.32% \n",
            "\n",
            "\tTrain Loss: 1.525 | Train Acc: 33.77%\n",
            "\t Val. Loss: 1.555 |  Val. Acc: 28.63% \n",
            "\n",
            "\tTrain Loss: 1.522 | Train Acc: 34.06%\n",
            "\t Val. Loss: 1.555 |  Val. Acc: 28.55% \n",
            "\n",
            "\tTrain Loss: 1.518 | Train Acc: 34.56%\n",
            "\t Val. Loss: 1.554 |  Val. Acc: 28.86% \n",
            "\n",
            "\tTrain Loss: 1.514 | Train Acc: 34.55%\n",
            "\t Val. Loss: 1.553 |  Val. Acc: 28.72% \n",
            "\n",
            "\tTrain Loss: 1.510 | Train Acc: 35.11%\n",
            "\t Val. Loss: 1.553 |  Val. Acc: 28.77% \n",
            "\n",
            "\tTrain Loss: 1.505 | Train Acc: 35.55%\n",
            "\t Val. Loss: 1.552 |  Val. Acc: 29.02% \n",
            "\n",
            "\tTrain Loss: 1.501 | Train Acc: 35.65%\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 29.11% \n",
            "\n",
            "\tTrain Loss: 1.497 | Train Acc: 36.02%\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 29.22% \n",
            "\n",
            "\tTrain Loss: 1.492 | Train Acc: 36.49%\n",
            "\t Val. Loss: 1.551 |  Val. Acc: 29.33% \n",
            "\n",
            "\tTrain Loss: 1.487 | Train Acc: 36.96%\n",
            "\t Val. Loss: 1.549 |  Val. Acc: 29.64% \n",
            "\n",
            "\tTrain Loss: 1.483 | Train Acc: 36.96%\n",
            "\t Val. Loss: 1.549 |  Val. Acc: 29.56% \n",
            "\n",
            "\tTrain Loss: 1.477 | Train Acc: 37.57%\n",
            "\t Val. Loss: 1.548 |  Val. Acc: 29.70% \n",
            "\n",
            "\tTrain Loss: 1.472 | Train Acc: 38.00%\n",
            "\t Val. Loss: 1.549 |  Val. Acc: 29.78% \n",
            "\n",
            "\tTrain Loss: 1.467 | Train Acc: 38.31%\n",
            "\t Val. Loss: 1.548 |  Val. Acc: 30.03% \n",
            "\n",
            "\tTrain Loss: 1.461 | Train Acc: 38.89%\n",
            "\t Val. Loss: 1.548 |  Val. Acc: 29.78% \n",
            "\n",
            "\tTrain Loss: 1.455 | Train Acc: 39.15%\n",
            "\t Val. Loss: 1.547 |  Val. Acc: 30.45% \n",
            "\n",
            "\tTrain Loss: 1.449 | Train Acc: 39.63%\n",
            "\t Val. Loss: 1.547 |  Val. Acc: 30.26% \n",
            "\n",
            "\tTrain Loss: 1.443 | Train Acc: 40.13%\n",
            "\t Val. Loss: 1.546 |  Val. Acc: 30.51% \n",
            "\n",
            "\tTrain Loss: 1.436 | Train Acc: 40.78%\n",
            "\t Val. Loss: 1.546 |  Val. Acc: 30.54% \n",
            "\n",
            "\tTrain Loss: 1.430 | Train Acc: 40.93%\n",
            "\t Val. Loss: 1.545 |  Val. Acc: 30.73% \n",
            "\n",
            "\tTrain Loss: 1.422 | Train Acc: 41.22%\n",
            "\t Val. Loss: 1.545 |  Val. Acc: 30.68% \n",
            "\n",
            "\tTrain Loss: 1.415 | Train Acc: 42.06%\n",
            "\t Val. Loss: 1.545 |  Val. Acc: 31.18% \n",
            "\n",
            "\tTrain Loss: 1.408 | Train Acc: 42.34%\n",
            "\t Val. Loss: 1.544 |  Val. Acc: 31.35% \n",
            "\n",
            "\tTrain Loss: 1.400 | Train Acc: 42.89%\n",
            "\t Val. Loss: 1.544 |  Val. Acc: 31.18% \n",
            "\n",
            "\tTrain Loss: 1.392 | Train Acc: 43.39%\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 31.18% \n",
            "\n",
            "\tTrain Loss: 1.384 | Train Acc: 43.90%\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 31.07% \n",
            "\n",
            "\tTrain Loss: 1.375 | Train Acc: 44.47%\n",
            "\t Val. Loss: 1.543 |  Val. Acc: 31.43% \n",
            "\n",
            "\tTrain Loss: 1.366 | Train Acc: 44.90%\n",
            "\t Val. Loss: 1.542 |  Val. Acc: 31.66% \n",
            "\n",
            "\tTrain Loss: 1.357 | Train Acc: 45.36%\n",
            "\t Val. Loss: 1.542 |  Val. Acc: 31.01% \n",
            "\n",
            "\tTrain Loss: 1.348 | Train Acc: 45.70%\n",
            "\t Val. Loss: 1.542 |  Val. Acc: 31.32% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "    \n",
        "    categories = {0: \"Very Negative\", 1:\"Negative\", 2:\"Neutral\", 3:\"Positive\", 4:\"Very Positive\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91a30194-3c2a-4116-fe9c-9c92ea1a5e32"
      },
      "source": [
        "classify_sentence(\"Jason X has cheesy effects and a hoary plot , but its macabre , self-deprecating sense of humor makes up for a lot .\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    }
  ]
}